# Touchless Reading Interface

A web-based gesture-controlled reading interface designed for hands-free
interaction in situational and accessibility-oriented contexts such as
cooking, laboratory work, and motor impairments.

## Project Overview
This project explores the design of a touchless reading UI that allows users
to scroll, zoom, adjust brightness, and highlight text using mid-air hand
gestures detected via a webcam.

The focus of this project is human–computer interaction (HCI), emphasizing
usability, accessibility, and low-effort interaction rather than novel
gesture recognition algorithms.

## Features (Planned)
- Gesture-based scrolling
- Pinch-to-zoom text resizing
- Brightness adjustment via hand gestures
- Sentence highlighting
- Visual feedback and gesture hints
- Accessibility-focused design

## Technology Stack
- HTML, CSS, JavaScript
- MediaPipe Hands (hand tracking)
- Runs entirely in the browser
- No backend or data storage

## How to Run (Development)
1. Open `index.html` in a modern browser
2. Allow webcam access when prompted
3. Stand approximately an arm’s length from the screen

## Notes
- Webcam input is processed locally in the browser
- No video data is stored or transmitted
